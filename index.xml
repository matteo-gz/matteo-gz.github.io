<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>matteo's blog</title><link>https://matteo-gz.github.io/</link><description>This is my cool site</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 23 May 2024 17:44:27 +0800</lastBuildDate><atom:link href="https://matteo-gz.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>supervisor搭建</title><link>https://matteo-gz.github.io/posts/supervisor/</link><pubDate>Thu, 23 May 2024 17:44:27 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/supervisor/</guid><description>pip install supervisor echo_supervisord_conf &amp;gt; /etc/supervisord.conf vim /etc/supervisord.conf append
[program:process1] command=/root/process1 autorestart=true supervisord -c /etc/supervisord.conf supervisorctl start process1 supervisorctl stop process1</description></item><item><title>排查网络</title><link>https://matteo-gz.github.io/posts/network_check/</link><pubDate>Sat, 27 Apr 2024 18:17:11 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/network_check/</guid><description>检查TCP端口连通性 nc -vz www.example.com 80 v是verbose mode
使用-z参数快速扫描端口状态,是否开放
window下powershell Test-NetConnection -ComputerName 127.0.0.1 -Port 6379
检查网络延时 mtr baidu.com -r 数字单位是ms,r是report的意思
ping ping检查范围限于ICMP协议
kill端口 window
# 寻找占用80端口 netstat -ano |findstr 80 # kill进程 taskkill /f /pid 28020 找到进程的启动命令 window环境
wmic process where &amp;#34;processid=1323&amp;#34; get processid,commandline</description></item><item><title>Redis实操记录</title><link>https://matteo-gz.github.io/posts/redis/</link><pubDate>Sat, 27 Apr 2024 00:18:43 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/redis/</guid><description>redis架构 目的: 针对不同的业务特性,选择合适的架构.
单机模式 一台redis节点,适合本地使用.
若机器挂了则无解.
主从模式 一台写节点,多台从节点,适合多读少写场景.
若写压力上来,则无解.
哨兵模式 写节点自动转移,满足高可用.适合多读少写场景.
若写压力上来,则有瓶颈.写节点挂了会转移,写节点会故障一段时间. 若不彻底解决写压力,无法根治问题.
集群模式 属于分布式架构,可以堆机器解决写压力.
redis连接数 目的: 提高应用性能,避免频繁的创建和销毁连接.
使用redis连接池.
需要埋点redis连接池的命中率.
若空闲连接持续为空,则明显连接数不够用需要提升.
根据业务压测,确定redis连接数的合理范围.
关闭连接 当应用关闭时,记得close连接.
redis缓存策略 获取redis缓存策略 config get maxmemory-policy 默认是noeviction
LRU与LFU算法 Least Recently Used :最近最少使用 Least Frequently Used : 最近最不常用 阿里云的redis策略是选择volatile-lru
redis.conf
maxmemory-policy volatile-lru 查询redis的热点key lfu算法下可使用redis-cli --hotkeys,查询redis的热点key.
线上排查 查找大key redis-cli --bigkeys
设置慢日志 # 慢日志长度 CONFIG GET slowlog-max-len # 设置 慢日志长度 CONFIG SET slowlog-max-len 128 设置慢日志时间
# 单位时间为微妙 CONFIG SET slowlog-log-slower-than 10000 获取慢日志</description></item><item><title>Go metrics</title><link>https://matteo-gz.github.io/posts/gometrics/</link><pubDate>Thu, 08 Feb 2024 10:20:57 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/gometrics/</guid><description><![CDATA[导入包 go get -u github.com/go-kratos/kratos/contrib/metrics/prometheus/v2 注册路由 // 导入pkg import &#34;github.com/prometheus/client_golang/prometheus/promhttp&#34; // http 服务注册此路由 router.Handle(&#34;/metrics&#34;, promhttp.Handler()) 验证是否引入metrics curl /metrics 可以看到默认的数据
定义一个指标 var _metricRequests = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: &#34;server&#34;, Subsystem: &#34;requests&#34;, Name: &#34;code_total&#34;, Help: &#34;The total number of processed requests&#34;, }, []string{&#34;kind&#34;, &#34;operation&#34;, &#34;code&#34;, &#34;reason&#34;}) 注册该指标 import &#34;github.com/prometheus/client_golang/prometheus&#34; prometheus.MustRegister(_metricRequests) 使用指标 var requests = prom.NewCounter(_metricRequests) requests.With(&#34;get&#34;, &#34;/&#34;, &#34;200&#34;, &#34;OK&#34;).Inc() 验证定义指标是否生效 当我们使用完指标后 即可查看
# HELP server_requests_code_total The total number of processed requests # TYPE server_requests_code_total counter server_requests_code_total{code=&#34;200&#34;,kind=&#34;get&#34;,operation=&#34;/&#34;,reason=&#34;OK&#34;} 1 具体代码 https://github.]]></description></item><item><title>小米解锁BL</title><link>https://matteo-gz.github.io/posts/xiaomiunlock/</link><pubDate>Sat, 30 Dec 2023 17:01:21 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/xiaomiunlock/</guid><description>这个办法是通过闲鱼APP上找人,利用UBL key解锁小米BL.
此方法需要消耗金钱,即购买UBL key的钱.
免费的方法为 https://github.com/MlgmXyysd/Xiaomi-HyperOS-BootLoader-Bypass ,但是无法解锁小米14之后的机型.
准备工作 下载客户端 https://xiaomikey.net/ window环境需要
下载驱动 https://xiaomiflashtool.com/
让xiaomikey客户端识别出小米手机,
理论上xiaomikey软件里面包含了xiaomiflash
下载ADB https://developer.android.com/tools/releases/platform-tools
将路径追加尽系统path.
adb devices 准备刷机 小米手机进入开发者模式 点击系统版本 连续点击5次 即可进入开发者模式
开发者模式下进行USB调试 要求
必须登录小米账号 必须插入sim卡 必须使用移动网络 在开发者模式下 打开允许USB调试.
电脑插入手机,手机选择信任电脑的连接.
adb进入fastboot模式 # 查看设备 adb devices # 进入fastboot adb reboot bootloader 登录xiaomikey 打开软件,选择 unlock boot- ubl key.
点击 unlock bootloader
此时会读取fastboot模式下的小米手机信息.
此时会生成 UBL token.
将UBL token 兑换成 UBL key.
然后填入UBL key 点击apply ubl key 可解锁.
过程中确保网络能连接小米服务器.
若操作失败 如果点击unlock bootloader后遇到duplicate token的话</description></item><item><title>socks5 协议</title><link>https://matteo-gz.github.io/posts/socks5/</link><pubDate>Wed, 13 Dec 2023 21:16:44 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/socks5/</guid><description>资料 rfc1928 SOCKS Protocol Version 5
https://datatracker.ietf.org/doc/html/rfc1928
socks5目标: TCP 和 UDP 域中的客户端-服务器应用程序提供一个框架，以便方便、安全地使用网络防火墙的服务
字节序 0x01234567 在字节顺序中表现
Big-Endian
0x100: 0x01 0x101: 0x23 0x102: 0x45 0x103: 0x67 Little-Endian
0x100: 0x67 0x101: 0x45 0x102: 0x23 0x103: 0x01 rfc1929 Username/Password Authentication for SOCKS V5
https://datatracker.ietf.org/doc/html/rfc1929
过程 1.TCP连接 3次握手后,客户端 连接 服务端socks5端口1080
2.协商环节 2.1.客户端发送给服务端 X'05&amp;rsquo; , X开头的数据都是十六进制
报文格式:
+----+----------+----------+ |VER | NMETHODS | METHODS | +----+----------+----------+ | 1 | 1 | 1 to 255 | +----+----------+----------+ 字段解释:</description></item><item><title>显卡相关</title><link>https://matteo-gz.github.io/posts/gpu/</link><pubDate>Sat, 12 Aug 2023 11:47:27 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/gpu/</guid><description>显卡挑选 原文which gpu for deep learning by Tim Dettmers - 2023/01/30
对此摘抄了 显卡工作原理 与 显卡关键因素
算力产品 AutoDL
显卡工作原理 结论 许多人说GPU快是因为 matrix multiplication 矩阵乘法 和 convolution 卷积 高效,Tim Dettmers认为是memory bandwidth 内存带宽.
内存带宽优点 CPU是延迟优化的,而GPU是带宽优化的.类比CPU是法拉利,GPU是大卡车, 在从 随机 A点 运货到 随机 B点 过程中,
CPU可以快速获取 RAM Random Access Memory 中的一些memory,而GPU则更慢(latency 延迟 要高得多), 但是CPU需要多次来回才能完成其工作,而GPU可以一次获取更多memory 内存.
CPU擅长快速获取少量内存(5 3 7), 而GPU擅长获取大量内存(矩阵乘法:(A*B)*C).
最好的CPU有大约 50GB/s,而最好的GPU有 750GB/s 的内存带宽.
如果计算操作需要的内存越多,GPU相对于CPU的优势就越明显.但是仍然存在可能会损害GPU性能的延迟.
一辆大卡车每次旅行可能都能拿起很多包裹,但问题是你要等很长时间,直到下一组包裹到达. 如果不解决这个问题,即使对于大量数据,GPU 也会非常慢.那么这个问题是如何解决的呢?
线程并行 如果你要求一辆大卡车进行多次旅行来取包裹,一旦卡车离开进行下一次旅行,你总是会等待很长时间才能收到下一批包裹——卡车只是很慢.
但是,如果您现在使用由法拉利和大型卡车组成的车队(线程并行),并且你有很多包裹(大块内存如 matrix 矩阵)的工作,那么你将等待第一辆卡车,
但在那之后你将根本没有等待时间 — 卸载包裹需要花费大量时间,以至于所有卡车都将在卸载位置B排队,以便你始终可以直接访问你的包裹(memory). 这有效地隐藏了延迟,以便GPU提供高带宽,同时在线程并行性下隐藏其延迟 — 因此对于大块内存,GPU提供最佳的内存带宽, 同时几乎没有由于线程并行延迟而导致的缺点.</description></item><item><title>Window偏好优化</title><link>https://matteo-gz.github.io/posts/win/</link><pubDate>Fri, 11 Aug 2023 15:19:51 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/win/</guid><description><![CDATA[杂项 默认展开win11的右键收缩菜单 How to Get Back Classic (Full) Context Menu in Windows 11
reg add HKCU\Software\Classes\CLSID\{86ca1aa0-34aa-4e8b-a509-50c905bae2a2}\InprocServer32 /ve /d &#34;&#34; /f window图标快捷箭头优化 How to remove arrows from shortcuts in Windows 11
REG ADD &#34;HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\Shell Icons&#34; /v 29 /t REG_SZ /d &#34;&#34; /f 分辨率 参考来源 【硬件科普】换了更高分辨率的显示器，软件界面反而模糊-Windows缩放详解
针对27寸 2K屏幕
DSR调整 Nvidia control panel &gt;&gt; 3D settings &gt;&gt; Manage 3D settings &gt;&gt; global settings &gt;&gt; DSR-Factors 选择2.25x DL
显示设置调整 display resolution 选择 3840x2160
Scale 选择 250%]]></description></item><item><title>llama2模型 类chatGPT产品体验</title><link>https://matteo-gz.github.io/posts/llama/</link><pubDate>Wed, 09 Aug 2023 22:27:59 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/llama/</guid><description>简介 一个语言模型,类似chatGPT. 可以本地部署, 下面列下规格
7b 需要6～8GB显存 13b 需要13～16GB显存 70b 需要48GB显存,可以2张4090 安装 申请和下载模型 点击 https://huggingface.co/meta-llama
选择模型 Llama2-chat,13B 下载
将会跳转到Facebook公司的申请界面,勾选协议,提交申请
平替方案 如果觉得麻烦
下载这个GGML模型 https://huggingface.co/TheBloke/Firefly-Llama2-13B-v1.2-GGML
firefly-llama2-13b-v1.2.ggmlv3.q6_K.bin
文件链接 https://huggingface.co/TheBloke/Firefly-Llama2-13B-v1.2-GGML/blob/main/firefly-llama2-13b-v1.2.ggmlv3.q6_K.bin
python虚拟环境 # 创建python虚拟环境 python -m venv ./venv # 进行python虚拟环境 ./venv/Script/activate 安装pytorch with cuda # https://pytorch.org/get-started/locally/ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 安装ui # 安装ui git clone https://github.com/oobabooga/text-generation-webui.git # 进入ui目录 cd text-generation-webui # 安装ui依赖 pip install -r requirements.txt # 修复bitsandbytes bug pip uninstall bitsandbytes pip install bitsandbytes-windows # 启动UI python server.</description></item><item><title>音频转文字 Whisper</title><link>https://matteo-gz.github.io/posts/whisper/</link><pubDate>Tue, 08 Aug 2023 19:31:19 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/whisper/</guid><description><![CDATA[简介 一个音频转文本的模型 https://github.com/openai/whisper
依赖 python ffmpeg 命令行使用 验证GPU 在venv环境下 输入whisper -h
&ndash;device # 如果默认是cpu 则证明cuda安装失败
# 这样也能验证cuda是否安装了 python -c &#34;import torch; print(torch.version.cuda)&#34; 重装torch gpu版本
# 卸载纯cpu版 pip uninstall torch # clean cache pip cache purge # copy from https://pytorch.org/get-started/locally/ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 再次验证 whisper -h
&ndash;device # 如果默认是cuda 则证明成功
运行demo
whisper {vocieFile} --model large-v2 --model_dir {modelPath} \ --ourput_dir {outputDir} --output_format txt --device cuda --language Chinese 界面版 界面版 https://github.]]></description></item></channel></rss>