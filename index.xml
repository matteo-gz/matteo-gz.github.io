<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>matteo's blog</title><link>https://matteo-gz.github.io/</link><description>This is my cool site</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 12 Aug 2023 11:47:27 +0800</lastBuildDate><atom:link href="https://matteo-gz.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>显卡相关</title><link>https://matteo-gz.github.io/posts/gpu/</link><pubDate>Sat, 12 Aug 2023 11:47:27 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/gpu/</guid><description>显卡挑选 原文which gpu for deep learning by Tim Dettmers - 2023/01/30
对此摘抄了 显卡工作原理 与 显卡关键因素
算力产品 AutoDL
显卡工作原理 结论 许多人说GPU快是因为 matrix multiplication 矩阵乘法 和 convolution 卷积 高效,Tim Dettmers认为是memory bandwidth 内存带宽.
内存带宽优点 CPU是延迟优化的,而GPU是带宽优化的.类比CPU是法拉利,GPU是大卡车, 在从 随机 A点 运货到 随机 B点 过程中,
CPU可以快速获取 RAM Random Access Memory 中的一些memory,而GPU则更慢(latency 延迟 要高得多), 但是CPU需要多次来回才能完成其工作,而GPU可以一次获取更多memory 内存.
CPU擅长快速获取少量内存(5 * 3 * 7), 而GPU擅长获取大量内存(矩阵乘法:(A*B)*C).
最好的CPU有大约 50GB/s,而最好的GPU有 750GB/s 的内存带宽.
如果计算操作需要的内存越多,GPU相对于CPU的优势就越明显.但是仍然存在可能会损害GPU性能的延迟.
一辆大卡车每次旅行可能都能拿起很多包裹,但问题是你要等很长时间,直到下一组包裹到达. 如果不解决这个问题,即使对于大量数据,GPU 也会非常慢.那么这个问题是如何解决的呢?
线程并行 如果你要求一辆大卡车进行多次旅行来取包裹,一旦卡车离开进行下一次旅行,你总是会等待很长时间才能收到下一批包裹——卡车只是很慢.
但是,如果您现在使用由法拉利和大型卡车组成的车队(线程并行),并且你有很多包裹(大块内存如 matrix 矩阵)的工作,那么你将等待第一辆卡车,
但在那之后你将根本没有等待时间 — 卸载包裹需要花费大量时间,以至于所有卡车都将在卸载位置B排队,以便你始终可以直接访问你的包裹(memory).</description></item><item><title>Window偏好优化</title><link>https://matteo-gz.github.io/posts/win/</link><pubDate>Fri, 11 Aug 2023 15:19:51 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/win/</guid><description><![CDATA[How to Get Back Classic (Full) Context Menu in Windows 11
reg add HKCU\Software\Classes\CLSID\{86ca1aa0-34aa-4e8b-a509-50c905bae2a2}\InprocServer32 /ve /d &#34;&#34; /f How to remove arrows from shortcuts in Windows 11
REG ADD &#34;HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\Shell Icons&#34; /v 29 /t REG_SZ /d &#34;&#34; /f ]]></description></item><item><title>llama2模型 类chatGPT产品体验</title><link>https://matteo-gz.github.io/posts/llama/</link><pubDate>Wed, 09 Aug 2023 22:27:59 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/llama/</guid><description>简介 一个语言模型,类似chatGPT. 可以本地部署, 下面列下规格
7b 需要6～8GB显存 13b 需要13～16GB显存 70b 需要48GB显存,可以2张4090 安装 申请和下载模型 点击 https://huggingface.co/meta-llama
选择模型 Llama2-chat,13B 下载
将会跳转到Facebook公司的申请界面,勾选协议,提交申请
平替方案 如果觉得麻烦
下载这个GGML模型 https://huggingface.co/TheBloke/Firefly-Llama2-13B-v1.2-GGML
firefly-llama2-13b-v1.2.ggmlv3.q6_K.bin
文件链接 https://huggingface.co/TheBloke/Firefly-Llama2-13B-v1.2-GGML/blob/main/firefly-llama2-13b-v1.2.ggmlv3.q6_K.bin
python虚拟环境 # 创建python虚拟环境 python -m venv ./venv # 进行python虚拟环境 ./venv/Script/activate 安装pytorch with cuda # https://pytorch.org/get-started/locally/ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 安装ui # 安装ui git clone https://github.com/oobabooga/text-generation-webui.git # 进入ui目录 cd text-generation-webui # 安装ui依赖 pip install -r requirements.txt # 修复bitsandbytes bug pip uninstall bitsandbytes pip install bitsandbytes-windows # 启动UI python server.</description></item><item><title>音频转文字 Whisper</title><link>https://matteo-gz.github.io/posts/whisper/</link><pubDate>Tue, 08 Aug 2023 19:31:19 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/whisper/</guid><description><![CDATA[简介 一个音频转文本的模型 https://github.com/openai/whisper
依赖 python ffmpeg 命令行使用 验证GPU 在venv环境下 输入whisper -h
&ndash;device # 如果默认是cpu 则证明cuda安装失败
# 这样也能验证cuda是否安装了 python -c &#34;import torch; print(torch.version.cuda)&#34; 重装torch gpu版本
# 卸载纯cpu版 pip uninstall torch # clean cache pip cache purge # copy from https://pytorch.org/get-started/locally/ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 再次验证 whisper -h
&ndash;device # 如果默认是cuda 则证明成功
运行demo
whisper {vocieFile} --model large-v2 --model_dir {modelPath} \ --ourput_dir {outputDir} --output_format txt --device cuda --language Chinese 界面版 界面版 https://github.]]></description></item><item><title>咒语生成图片 Stable Diffusion web UI</title><link>https://matteo-gz.github.io/posts/stablediffusionwebui/</link><pubDate>Tue, 08 Aug 2023 11:20:56 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/stablediffusionwebui/</guid><description>简介 旨在个人快速回忆Stable Diffusion相关关系
Stable Diffusion 是一个深度学习,文转图模型.
Stable Diffusion web UI 即面向用户提供界面操作工具, 链接为
https://github.com/AUTOMATIC1111/stable-diffusion-webui
其中该界面为英语,支持汉化插件
https://github.com/VinsonLaro/stable-diffusion-webui-chinese
PyTorch 官网 https://pytorch.org/ 是一个深度学习的框架
我的安装选择
OS: Windows package: pip language: python compute Platform: CUDA 教程 https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki
启动 下载完web UI后,运行webui-user.bat即可
在运行过程避免不了报错,很考验python debug能力。
初始化
设置webui-user.bat参数
set PYTHON= #python文件路径 set GIT= # git文件路径 set VENV_DIR= # venv目录 set COMMANDLINE_ARGS=--xformers # 启动参数 将python,git的bin path 加入系统环境变量下的path。
另外确保安装了Microsoft Visual C++ Redistributable vc_redist.x64.exe
安装过程需要网络稳定,需要下载很多pkg
缓存冲突解决
直接删除./venv/lib/site-packages/下冲突的包,重新运行脚本.
或者命令行搞定
# 卸载具体包 pip uninstall 具体包 # clean cache pip cache purge 模型位置</description></item><item><title>关于Go代码生成</title><link>https://matteo-gz.github.io/posts/gencode/</link><pubDate>Mon, 07 Aug 2023 16:24:58 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/gencode/</guid><description>目的 Go Kitex提供了自定义模板生成代码,使用起来挺方便的.
有望改造成支持公司内部go代码生成工具
https://www.cloudwego.io/zh/docs/kitex/tutorials/code-gen/custom_tpl/ 处理要素 cli工具整合 这里推荐2个包,封装了cli和参数解析
https://github.com/spf13/cobra https://github.com/spf13/pflag 基本数据对象定义 提供了文件生成时的数据渲染对象 PackageInfo
模板渲染使用html/template语法
额外参数在context中解析 cli传递参数过多会带来复杂性,需要额外的.json文件数据提供在上下文中解析.
多模板文件定义 通过指定目录加载其下所有模板文件
模板文件格式为.yaml
生成的文件路径也支持变量解析.
其中能独立定义新增代码部分
统一入口 初始化和更新行为都为同一命令,减少处理成本
额外点 多任务并行处理文件生成 跨平台支持</description></item><item><title>go pkg包设计</title><link>https://matteo-gz.github.io/posts/component/</link><pubDate>Mon, 07 Aug 2023 15:28:13 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/component/</guid><description><![CDATA[设计考虑 以下是个人的建议,随便看看了解下
context支持 一般入参数context是第一个参数,提供了timeout机制
logger接口定义 在组件的初始化时,将使用方的日志实例进行接口约束,
要求实现其debug,error级别method.
可以参考gorm的logger设计
hook注入 方便使用方对metric的收集,可以参考redis hook设计
布局了解 这里只是提供参考建议
go官方 https://github.com/golang-standards/project-layout 知道internal目录对内部系统的保护
链接 https://go.dev/doc/go1.4#internalpackages 跨平台支持 查看支持平台
go tool dist list 条件编译约束
//go:build (linux &amp;&amp; 386) || (darwin &amp;&amp; !cgo) https://pkg.go.dev/cmd/go#hdr-Build_constraints
linters集成 https://golangci-lint.run/ 提高代码质量
版本约束 具体查看 https://go.dev/ref/mod#versions
依赖注入 https://github.com/google/wire
使得依赖关系变得整洁
参数配置 Functional Options Pattern,代码优雅
IDL https://protobuf.dev/ 利用protobuf提供接口和配置的定义.
验证项目得分 https://goreportcard.com/
评估项含
gofmt go vet go lint gocyclo ]]></description></item><item><title>聊天系统设计调研</title><link>https://matteo-gz.github.io/posts/im/</link><pubDate>Mon, 07 Aug 2023 12:23:04 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/im/</guid><description>总体架构分层
接入层,无状态 逻辑层 存储层 这里是参考了陌陌设计
连接层 这里有2种方案选择
WebSocket MQTT 关于MQTT,有EMQX中间件.
消息上线可以走HTTP接口,即客户端发给服务端消息
消息下行可以走EMQX订阅主题,即服务端推送消息给客户端
连接层属于无状态,支持水平扩展.
逻辑层 通用消息格式定制
以及业务路由分发决策
设计规则
不丢消息 需要业务ACK机制
消息去重 服务端与客户端都需要做到
时序一致性 可以用snowflake算法.
利用局部性原理减少id生成器压力,有利于水平扩展
缓存设计 由于实时系统,基本上有一层cache,类似内核系统的buffer。
多级缓冲,面向c端场景的话一般链路不会太长,而且要考虑数据回种,分布式一致性挑战.
大概local cache -&amp;gt; redis （读写分离)-&amp;gt; database（读写分离)
其他考虑场景 接入APP推送 接入风控 数据多端同步 多条消息打包与压缩格式设计 万人大群的数据扇出 明星突发性空降某频道 数据埋点监控 系统自动扩容 存储层 离线消息 如果需求量不大,Mysql即可以解决.
聊天应用的读写比例大概是1:1.
数据库 Cassandra
Discord公司有在用.偏向AP场景
HBase
Facebook公司有在用.偏向CP场景
个人想法 前期用Mysql,但是封装一层接口,为后期数据库迁移作准备.
大数据库选择要还看云数据库商支持程度,说不定还有其他云产品合适.
对象存储 minio
消息队列 rabbitMQ比较适合业务,
但是追求高吞吐的kafka,自己必须封装多一层机制来保证业务的一致性.</description></item><item><title>go微服务框架使用总结</title><link>https://matteo-gz.github.io/posts/goframe/</link><pubDate>Tue, 18 Jul 2023 13:03:09 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/goframe/</guid><description>记录下自己使用下来的go微服务框架,kratos go-zero kitex.
kratos bilibili公司出品的框架,当年公司内部代码泄漏,现在开源优化已经到了v2版本.
参考了DDD,Clean Architecture 设计理念.
项目结构清晰,每一层级的角色定位清晰,没有全局变量污染,还引入了wire进行依赖倒置.
data层暴露了clean up函数对资源句柄进行回收.
框架层与业务层解耦,框架生命周期感知清晰.
组件开放接口设计,扩展性强
服务使用的是GRPC+Protocol Buffer, 同一服务进程下暴露了GRPC端口和HTTP端口.
HTTP是通过protoc组件protoc-gen-go-http反射路由到同一RPC方法.
框架整体设计比较轻量,适合自己组合微服务方案.
总结 适合团队有架构组的人使用,前期需要自己组合方案,整合组件.后期基本完善,使用体验良好. HTTP层建议使用gin框架,因为protoc-gen-go-http适合开发阶段调试用,重度需求满足不了,自己做适配一路都是新坑.
Go-zero 一个公司CTO主推项目,加入了CNCF.
HTTP单独部署一个项目,路由方法定义通过编写.api后缀文件(Go-zero定义的语法)实现.
他们的设计理念是实用性.
总结 生产上能用。对于定制化业务,直接fork他们官方的cli工具,然后公司内部修改维护该仓库.
Kitex 字节跳动公司的开源项目,分RPC框架Kitex和HTTP框架Hertz.
2个框架是2个团队的产物,设计规范不一致.
框架替换原有了go/net设计,实现高性能.(生产稳定性需要查阅官方资料验证)
IDL支持Thrift,官方对Thrift的支持度很高,因为他们内部使用Thrift,但也支持Protobuf.
他们的设计理念是高性能
总结 Kitex只是cloudwego组织下子项目,Thrift不是特别吸引我, 希望cloudwego/netpoll能封装成一个适配性高组件.</description></item><item><title>体验switch游戏</title><link>https://matteo-gz.github.io/posts/switchgame/</link><pubDate>Sat, 06 May 2023 19:31:52 +0800</pubDate><author>Author</author><guid>https://matteo-gz.github.io/posts/switchgame/</guid><description>主机游戏 steam的单机游戏体验过一段时间后,随后了解到还有塞尔达传说王国之泪这样的游戏存在,有别于艾尔登法环这种 但是他只能在任天堂的switch上可以下载游玩,有别于pc游戏是主机游戏来的.
模拟器 pc上也存在着模拟switch游戏环境的模拟软件,yuzu模拟器和ryujinx模拟器,接下来我将体验下ryujinx模拟器上游玩主机游戏
ryujinx模拟器体验 下载 下载模拟器https://github.com/Ryujinx/release-channel-master/releases
我选了当前最新的1.1.762版本 https://github.com/Ryujinx/release-channel-master/releases/download/1.1.762/test-ava-ryujinx-1.1.762-win_x64.zip
先决 下载安装后,看了一眼官网wikihttps://github.com/Ryujinx/Ryujinx/wiki
在模拟器的目录下新建portable目录,需要导入任天堂switch相关的Keys和Firmware,即密钥和系统固件的意思,2者的版本还必须一致.
游戏格式 接下来就是导入游戏包xci格式的,就可以在模拟器的目录上看到该游戏，点击游玩即可。
游戏DLC或者游戏更新包之类的安装文件大多是nsp格式的,在游戏上进行管理导入即可。
switch游戏的外挂是金手指这个称呼,可以搜switch对应game的cheat code主题。
总结 模拟器比较吃cpu资源,很多时候成为瓶颈.相比于switch游戏画面和帧数比较高,而且还可以开作弊码,省去重复的游戏体验。
switch的优势就是携带游玩方便,类似手机于pc的存在,但是steam deck是linux系统也可以安装模拟器,也有这个优势.
另一个就是switch可以联网官方服务器游玩比较方便,但是局域网联机游玩模拟器似乎也能做到。
随着一款游戏的了解,我慢慢发现任天堂的理念是以游戏趣味性为主导,switch设备为游戏圈子所建立的生态, 其他游戏像是一座座高山,但是switch游戏就像一条弯弯曲曲的河流那样的存在</description></item></channel></rss>